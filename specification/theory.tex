\section{Theory (William)}

\subsection{Framing and error correction}
With a main objective of delivering frame-based error correction, one goal is to correctly identify where the frames start and end. Therefore, each frame has to be separated with an ASM when constructing the data stream and the system will look for the same word when separating the frames. Inspired by the text “Frame Synchronization” it has been decided to use the ASM “1ACFFC1D”, as this word will be harder to confuse with other, random bits.

Due to channel noise, it can’t be assumed that the ASMs and frames will be sent without errors and the ASM may be found at alternative positions. Therefore, two ASMs with correct distance between each other to contain a frame has to be identified before defining the content between the two as a frame.

To keep up with a high-capacity network, the plan is to use forward-error-correction with the (64,57,4) extended Hamming code to identify and correct errors in the information bits. This works by using product code. Here, the system will fill a 64 times 64 bits frame with 57 times 57 information bits and then add seven parity bits to each row and column and an additional seven times seven parity bits of parity bits in the end. This procedure enables the possibility to correct single errors and detect double errors.

The last thing to keep in mind is how to separate the data from the audio and the video group. This means that some additional information will be included in the beginning of each frame. This information will describe the contents of the frame and include a frame number, which has to contain enough bits to handle the large delay (e.g 16 bits), and two pointers telling where the data from the audio group and the video groups ends. This way, the data can be separated from each group when deframing it and sending it to the right group.

\subsection{Synchronisation}
A FiFo will be used when receiving and passing on data to audio and video groups, while passing and receiving data from the modulation groups will be handled by IQ signals. This means that there must be carefully chosen (or negotiated) a clock frequency higher than the ones used by the audio and video group. Otherwise, the other groups will overwrite their own data in the FiFo before it has been chaptered by us.

Since the modulation group doesn’t have the bigger picture of the data stream, they may confuse the IQ signals and send an inverted I or Q signal instead of the right one Therefore, the data must be evaluated when received and re-inverted in case of any inverted signals.
